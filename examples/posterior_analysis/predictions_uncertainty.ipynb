{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9257ef-58eb-432d-afd2-d4f1c87f4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib import colors\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Add module to path\n",
    "module_path = Path.cwd().parents[1] / \"module\"  \n",
    "sys.path.append(str(module_path))\n",
    "\n",
    "from pool_utils import (init_pool, \n",
    "                        PINNDataset, \n",
    "                        polar_grid_flat, \n",
    "                        normalize, \n",
    "                        train_test_files, \n",
    "                        select_inputs_outputs, \n",
    "                        compute_scaling_factor)\n",
    "\n",
    "from select_sensors import add_sensor_pool\n",
    "from model import PINN_model\n",
    "\n",
    "\n",
    "def plot_uncertainties_2d_MC(model, \n",
    "                             current_dataset,\n",
    "                             next_dataset,\n",
    "                             x_max, \n",
    "                             u_a, \n",
    "                             R, \n",
    "                             save_dir=None, \n",
    "                             prefix=None, \n",
    "                             n_samples=50, \n",
    "                             device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo Dropout to quantify mean and std \n",
    "    of ux and uy on 2D grid.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        \"font.size\": 7,\n",
    "        \"axes.labelsize\": 7,\n",
    "        \"xtick.labelsize\": 7,\n",
    "        \"ytick.labelsize\": 7,\n",
    "        \"legend.fontsize\": 7\n",
    "    })\n",
    "    \n",
    "    # current inputs and masks\n",
    "    current_inputs = current_dataset.inputs.cpu().detach().numpy()\n",
    "    current_x_all, current_y_all = current_inputs[:, 0]*x_max, current_inputs[:, 1]*x_max\n",
    "    current_is_data = current_dataset.is_data.cpu().numpy()\n",
    "\n",
    "    # Next inputs and masks\n",
    "    next_inputs = next_dataset.inputs.cpu().detach().numpy()\n",
    "    next_x_all, next_y_all = next_inputs[:, 0]*x_max, next_inputs[:, 1]*x_max\n",
    "    next_is_data = next_dataset.is_data.cpu().numpy()\n",
    "\n",
    "    s = 15  \n",
    "\n",
    "    # --- Regular grid ---\n",
    "    N = 200\n",
    "    x = np.linspace(-1.1, 1.1, N)\n",
    "    y = np.linspace(-1.1, 1.1, N)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    xy = torch.tensor(np.stack([X.flatten(), Y.flatten()], axis=1), dtype=torch.float32).to(device)\n",
    "\n",
    "    # ---  MC Dropout sampling ---\n",
    "    ux_samples = []\n",
    "    uy_samples = []\n",
    "    model.train()  \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            ux_pred, uy_pred = model(xy)\n",
    "            ux_pred = -ux_pred.cpu().numpy() * u_a.cpu().numpy()\n",
    "            uy_pred = -uy_pred.cpu().numpy() * u_a.cpu().numpy()\n",
    "            ux_samples.append(ux_pred)\n",
    "            uy_samples.append(uy_pred)\n",
    "\n",
    "    ux_samples = np.stack(ux_samples, axis=0)\n",
    "    uy_samples = np.stack(uy_samples, axis=0)\n",
    "\n",
    "    # --- Mean and var ---\n",
    "    ux_mean = np.mean(ux_samples, axis=0).reshape(N, N)\n",
    "    uy_mean = np.mean(uy_samples, axis=0).reshape(N, N)\n",
    "    ux_var = np.var(ux_samples, axis=0).reshape(N, N)\n",
    "    uy_var = np.var(uy_samples, axis=0).reshape(N, N)\n",
    "\n",
    "    # --- Total uncertainty ---\n",
    "    total_uncertainty = ux_var + uy_var\n",
    "\n",
    "    # --- Mask tunnel ---\n",
    "    X_scaled, Y_scaled = X * x_max, Y * x_max\n",
    "    mask = X_scaled**2 + Y_scaled**2 <= R**2\n",
    "    for arr in [ux_mean, uy_mean, total_uncertainty]:\n",
    "        arr[mask] = np.nan\n",
    "\n",
    "    # --- Plot function ---\n",
    "    def plot_field(Z, title, fname, cmap=\"RdBu_r\", figsize=(5/2.54,5/2.54), nature='uncertainties'):\n",
    "        \n",
    "        if nature == 'disp':\n",
    "            fig_width = figsize[0] * 1.35 \n",
    "            fig_height = figsize[1] * 1.35 \n",
    "            figsize_adjusted = (fig_width, fig_height)\n",
    "        else:\n",
    "            fig_width = figsize[0] * 1.0 \n",
    "            fig_height = figsize[1] * 1.0 \n",
    "            figsize_adjusted = (fig_width, fig_height)\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=figsize_adjusted)\n",
    "\n",
    "        if nature == 'uncertainties':\n",
    "            ax.scatter(\n",
    "                current_x_all[current_is_data],\n",
    "                current_y_all[current_is_data],\n",
    "                s=s,\n",
    "                facecolors='white',\n",
    "                edgecolors='black',\n",
    "                marker='x',\n",
    "                label='Current measurements',\n",
    "                linewidths=0.6,\n",
    "                zorder=4\n",
    "            )\n",
    "            ax.scatter(\n",
    "                next_x_all[next_is_data],\n",
    "                next_y_all[next_is_data],\n",
    "                s=s,\n",
    "                color='black',\n",
    "                marker='x',\n",
    "                label='Next measurements',\n",
    "                linewidths=0.6,\n",
    "                zorder=4\n",
    "            )\n",
    "\n",
    "        # Contour\n",
    "        if nature == 'uncertainties':\n",
    "            norm = colors.PowerNorm(gamma=0.7, vmin=0, vmax=np.nanmax(Z))\n",
    "            cf = ax.contourf(X_scaled, Y_scaled, Z, levels=100, cmap=cmap, extend=\"both\", norm=norm)\n",
    "            \n",
    "        else:\n",
    "            cf = ax.contourf(X_scaled, Y_scaled, Z, levels=50, cmap=cmap, extend=\"both\")\n",
    "\n",
    "\n",
    "        # Colorbar \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"6%\", pad=0.1)\n",
    "        cbar = plt.colorbar(cf, cax=cax)\n",
    "\n",
    "            \n",
    "        # Scientific writing\n",
    "        formatter = ScalarFormatter(useMathText=True)\n",
    "        formatter.set_powerlimits((0, 0))  \n",
    "        cbar.ax.yaxis.set_major_formatter(formatter)\n",
    "        \n",
    "        offset_text = cbar.ax.yaxis.get_offset_text()\n",
    "        offset_text.set_fontsize(6)\n",
    "        offset_text.set_x(3.5)  \n",
    "\n",
    "        # Units\n",
    "        if nature == 'disp':\n",
    "            plt.text(3.60, 1.09, \"(m)\", transform=plt.gca().transAxes)\n",
    "\n",
    "        cbar.ax.tick_params(labelsize=6)\n",
    "\n",
    "        # Tunnel wall\n",
    "        circle = plt.Circle((0,0), R, color='red', fill=False, linewidth=1)\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "        # Axes and grid\n",
    "        ax.set_xlabel(r\"$x$ (m)\")\n",
    "        ax.set_ylabel(r\"$y$ (m)\")\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "        x_min, x_max = -20, 20\n",
    "        y_min, y_max = -20, 20\n",
    "        step = 10\n",
    "        ax.set_xticks(np.arange(x_min, x_max+1, step))\n",
    "        ax.set_yticks(np.arange(y_min, y_max+1, step))\n",
    "        ax.grid(True, which='both', linewidth=0.5)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if save_dir is not None:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            save_path = os.path.join(save_dir, fname)\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    # --- TracÃ©s ---\n",
    "    plot_field(ux_mean, r\"$\\overline{u_x}$\", f\"ux_mean{('_'+prefix) if prefix else ''}.pdf\", figsize=(5/2.54,5/2.54), nature='disp')\n",
    "    plot_field(uy_mean, r\"$\\overline{u_y}$\", f\"uy_mean{('_'+prefix) if prefix else ''}.pdf\", figsize=(5/2.54,5/2.54), nature='disp')\n",
    "    plot_field(total_uncertainty, r\"$\\sigma(u_x)+\\sigma(u_y)$\", f\"u_var_current_next{('_'+prefix) if prefix else ''}.pdf\", cmap=\"viridis\", figsize=(7/2.54,7/2.54), nature='uncertainties')\n",
    "\n",
    "\n",
    "### Fix seed \n",
    "seed = 10\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# St Martin La Porte (Vu et al 2013)\n",
    "# Initial stress\n",
    "sigma_v = 5e6\n",
    "K = 0.75\n",
    "sigma_h = K*sigma_v\n",
    "l = 1\n",
    "\n",
    "# Rotation\n",
    "beta = 45*np.pi/180 # \n",
    "\n",
    "# In situ stress\n",
    "sigma_v_0 = sigma_v/2*(1+K + (1-K)*np.cos(2*beta))\n",
    "sigma_h_0 = sigma_v/2*(1+K - (1-K)*np.cos(2*beta))\n",
    "tau_vh_0 = sigma_v/2*(1-K)*np.sin(2*beta)\n",
    "\n",
    "# Tunnel radius\n",
    "R = 5\n",
    "\n",
    "# Extensometer length (0 if bc only)\n",
    "L = 24 # 8 \n",
    "\n",
    "# Mechanical parameters to retrieve\n",
    "Eh = 620e6\n",
    "Ev = 340e6\n",
    "Gvh = 200e6\n",
    "nh = 0.12\n",
    "nhv = 0.2\n",
    "nvh = Ev*nhv/Eh\n",
    "\n",
    "# Noise\n",
    "noise_level = 0\n",
    "\n",
    "# Path to repo root\n",
    "repo_root = Path.cwd().parents[1] \n",
    "\n",
    "# mode\n",
    "mode = \"extensometer\"\n",
    "\n",
    "# folder name\n",
    "folder = f\"7_sensors_{mode}_mode_Noise_0%\"\n",
    "\n",
    "# Path to data file\n",
    "load_dir = os.path.join(repo_root, \"examples\", f\"{mode}_mode\", \"Results\", f\"{folder}\") \n",
    "save_dir = os.path.join(repo_root, \"examples\", f\"{mode}_mode\", \"Results\", f\"{folder}\", \"posterior_analysis\", \"predictions\") \n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# seed dir\n",
    "seed_dir = os.path.join(load_dir, f\"s_{seed}\")\n",
    "\n",
    "save_path = os.path.join(load_dir, seed_dir, \"all_results.pkl\")\n",
    "if not os.path.exists(save_path):\n",
    "    print(f\"Warning: {save_path} does not exist, skipping\")\n",
    "    \n",
    "with open(save_path, \"rb\") as f:\n",
    "    results_dict = pickle.load(f)\n",
    "\n",
    "# List all steps in this seed folder\n",
    "seed_path = os.path.join(load_dir, seed_dir)  \n",
    "step_dirs = [d for d in os.listdir(seed_path) if d.startswith(\"step_\")]  \n",
    "step_dirs.sort(key=lambda x: int(x.split(\"_\")[1])) \n",
    "\n",
    "step = 3\n",
    "step_dir = step_dirs[step]\n",
    "\n",
    "load_path = os.path.join(load_dir, seed_dir, step_dir, f\"step_{step}.pth\")\n",
    "\n",
    "if not os.path.exists(load_path):\n",
    "    raise ValueError(f\"Path does not exist: {load_path}\")\n",
    "\n",
    "checkpoint = torch.load(load_path, weights_only=True)\n",
    "state_dict = checkpoint[\"model_state_dict\"]\n",
    "\n",
    "# Define layers\n",
    "width = 40\n",
    "depth = 10\n",
    "layers = [2]\n",
    "for _ in range(depth):\n",
    "    layers.append(width)\n",
    "print(layers)\n",
    "\n",
    "# Define model\n",
    "model = PINN_model(layers, nhv=nhv, nh=nh, beta=beta).to(device)\n",
    "\n",
    "# Load model states\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "# Collect x_max et u_a\n",
    "test_dataset = results_dict[\"test_dataset\"]\n",
    "inputs_test = test_dataset.inputs\n",
    "_, _, x_max, u_a = normalize(inputs_test, outputs=None, R=R, L=L, device=device)\n",
    "\n",
    "\n",
    "#-----------------------------\n",
    "#------- Current Dataset -----\n",
    "#-----------------------------\n",
    "\n",
    "# ------ Define grid ----\n",
    "inputs_grid, mask_int_selected_grid, mask_bc_selected_grid = polar_grid_flat(\n",
    "                                                                            R, \n",
    "                                                                            L, \n",
    "                                                                            Nr=10, \n",
    "                                                                            Ntheta=36, \n",
    "                                                                            refine_exponent=1, \n",
    "                                                                            select_every_r=1,\n",
    "                                                                            select_every_theta=1,\n",
    "                                                                            device=device,\n",
    "                                                                        )\n",
    "\n",
    "inputs_grid_scaled, *_ = normalize(inputs_grid, None, R, L)\n",
    "\n",
    "# train files\n",
    "data_dir = os.path.join(repo_root, \"synthetic_data\")    \n",
    "selected_ids = None \n",
    "train_files = train_test_files(data_dir, selected_ids=selected_ids)\n",
    "\n",
    "# Split inputs outputs train\n",
    "all_inputs_train, all_outputs_train, all_unique_ids_train, all_ext_ids_train = select_inputs_outputs(files=train_files, \n",
    "                                                                                                     noise_level=noise_level,\n",
    "                                                                                                     device=device)\n",
    "# --- Scale inputs / outputs ---\n",
    "all_inputs_train_scaled, all_outputs_train_scaled, x_max, u_a = normalize(all_inputs_train, all_outputs_train, R, L, device=device)\n",
    "\n",
    "# --- Scaling factor --- \n",
    "b = compute_scaling_factor(sigma_v, x_max, u_a)\n",
    "\n",
    "# --- Train pool --- \n",
    "current_pool = init_pool(\n",
    "                            all_inputs_scaled=all_inputs_train_scaled,\n",
    "                            all_outputs_scaled=all_outputs_train_scaled,\n",
    "                            sensor_ids=all_ext_ids_train,\n",
    "                            R=R,\n",
    "                            x_max=x_max,\n",
    "                            all_inputs_grid_scaled=inputs_grid_scaled,\n",
    "                            mask_int_selected_grid=mask_int_selected_grid,\n",
    "                            mask_bc_selected_grid=mask_bc_selected_grid,\n",
    "                            tol=1e-4,\n",
    "                            device=device\n",
    "                        )\n",
    "\n",
    "# initialization\n",
    "sensor_ids_list = [10, 19]\n",
    "current_pool = add_sensor_pool(model=None, \n",
    "                               pool=current_pool, \n",
    "                               sensor_type='extensometer', \n",
    "                               sensor_ids_list=sensor_ids_list, \n",
    "                               n_MC=50, \n",
    "                               random=False, \n",
    "                               device=device)\n",
    "\n",
    "\n",
    "# current\n",
    "sensor_ids_list = [32]\n",
    "current_pool = add_sensor_pool(model=None, \n",
    "                               pool=current_pool, \n",
    "                               sensor_type=mode, \n",
    "                               sensor_ids_list=sensor_ids_list, \n",
    "                               n_MC=50, \n",
    "                               random=False, \n",
    "                               device=device)\n",
    "\n",
    "\n",
    "# --- Training dataset ---\n",
    "current_dataset = PINNDataset(current_pool, \n",
    "                                 include_int=True, \n",
    "                                 include_bc=True, \n",
    "                                 include_data=True, \n",
    "                                 device=device)\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------\n",
    "#------- Next Dataset --------\n",
    "#-----------------------------\n",
    "next_pool = init_pool(\n",
    "                        all_inputs_scaled=all_inputs_train_scaled,\n",
    "                        all_outputs_scaled=all_outputs_train_scaled,\n",
    "                        sensor_ids=all_ext_ids_train,\n",
    "                        R=R,\n",
    "                        x_max=x_max,\n",
    "                        all_inputs_grid_scaled=inputs_grid_scaled,\n",
    "                        mask_int_selected_grid=mask_int_selected_grid,\n",
    "                        mask_bc_selected_grid=mask_bc_selected_grid,\n",
    "                        tol=1e-4,\n",
    "                        device=device\n",
    "                        )\n",
    "\n",
    "sensor_ids_list = [28]\n",
    "\n",
    "\n",
    "next_pool = add_sensor_pool(model=None, \n",
    "                            pool=next_pool, \n",
    "                            sensor_type=mode, \n",
    "                            sensor_ids_list=sensor_ids_list, \n",
    "                            n_MC=50, \n",
    "                            random=False, \n",
    "                            device=device)\n",
    "\n",
    "\n",
    "next_dataset = PINNDataset(next_pool, \n",
    "                           include_int=True, \n",
    "                           include_bc=True, \n",
    "                           include_data=True, \n",
    "                           device=device)\n",
    "\n",
    "#-----------------------\n",
    "#--------- Plot --------\n",
    "#-----------------------\n",
    "plot_uncertainties_2d_MC(model, \n",
    "                         current_dataset,\n",
    "                         next_dataset,\n",
    "                         x_max, \n",
    "                         u_a, \n",
    "                         R, \n",
    "                         save_dir=save_dir, \n",
    "                         prefix=f\"step_{step}_{mode}_mode\", \n",
    "                         n_samples=50, \n",
    "                         device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4cb688-420d-4b0e-b826-99d24d3bef50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
